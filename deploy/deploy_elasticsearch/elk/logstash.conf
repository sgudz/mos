input {
  file {
    path => "/var/log/remote/*.domain.tld/haproxy.log"
#    path => "/opt/stack/haproxy.log"
    exclude => "*.gz"
    start_position => "beginning"
    add_field => { "source" => "haproxy" }
  }
  file {
    path => [
              "/var/log/remote/*.domain.tld/neutron*",
              "/var/log/remote/*.domain.tld/nova*",
              "/var/log/remote/*.domain.tld/keystone*",
              "/var/log/remote/*.domain.tld/glance*",
              "/var/log/remote/*.domain.tld/cinder*",
              "/var/log/remote/*.domain.tld/heat*",
              "/var/log/remote/*.domain.tld/swift*",
              "/var/log/remote/*.domain.tld/ceilometer*",
              "/var/log/remote/*.domain.tld/sahara*",
              "/var/log/remote/*.domain.tld/murano*",
              "/var/log/remote/*.domain.tld/kernel*",
              "/var/log/remote/*.domain.tld/rabbit*"
            ]
#    path => "/opt/stack/service.log"
    exclude => "*.gz"
    start_position => "beginning"
    add_field => { "source" => "service" }
  }
}

filter {
  # strip fuel prefix
  grok {
    patterns_dir => "/opt/stack/elk/patterns"
    match => { "message" => "%{MOS_FUEL_PREFIX}" }
  }

  if [fuel_level] == "debug" {
    # ignore debug messages
    drop {}
  }

  if "_grokparsefailure" not in [tags] {
    mutate {
      rename => [ "fuel_message", "message" ]
      rename => [ "fuel_timestamp", "timestamp" ]
      rename => [ "fuel_level", "level" ]
    }
  }

  mutate {
    remove_tag => [ "_grokparsefailure" ]
  }

  if [source] == "haproxy" {
    grok {
      patterns_dir => "/opt/stack/elk/patterns"
      match => { "message" => "%{HAPROXY5_TRAFFIC}" }
    }

    if "_grokparsefailure" not in [tags] {
      # traffic log, check if it matches tcp or http

      mutate {
        rename => [ "haproxy_message", "message" ]
        rename => [ "haproxy_timestamp", "timestamp" ]
      }

      grok {
        patterns_dir => "/opt/stack/elk/patterns"
        match => { "message" => "%{HAPROXY5_TCP_SF}" }
      }

      if "_grokparsefailure" in [tags] {
        # try http
        grok {
          patterns_dir => "/opt/stack/elk/patterns"
          match => { "message" => "%{HAPROXY5_HTTP_SF}" }
        }
      }

      if "_grokparsefailure" not in [tags] {
        # message parsed successfully, remove it
        mutate {
          remove_field => [ "message" ]
        }
      }

      # ignore info-level messages with success report
      if [level] == "info" and (![http_status_code] or [http_status_code] < 400) and
            (![termination_state] or [termination_state] == "--" or [termination_state] == "----") {
        drop {}
      }
    }

  } else if [source] == "service" {

    grok {
      patterns_dir => "/opt/stack/elk/patterns"
      match => { "message" => "%{MOS_SERVICE}" }
    }

    if "_grokparsefailure" not in [tags] {
      mutate {
        rename => [ "service_message", "message" ]
        rename => [ "service_timestamp", "timestamp" ]
        rename => [ "service_level", "level" ]
      }
    }
  }

  if ![level] {
    # wasn't able to parse anything, drop it
    drop {}
  }

  mutate {
    remove_tag => [ "_grokparsefailure" ]
  }

  mutate {
    lowercase => [ "level" ]
    gsub => [ "level", "^err$", "error" ]
  }

  # use the date of receive by fuel
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS" ]
  }

  grok {
    # extract node name and log file from the path
    match => { "path" => "(?<node>node-\d+).+?/(?<filename>.*)" }
  }

  mutate {
    remove_field => [ "path", "haproxy_monthday", "haproxy_month",
        "haproxy_year", "haproxy_time", "haproxy_hour", "haproxy_minute",
        "haproxy_second", "haproxy_milliseconds", "timestamp" ]
  }
}

output {
#  stdout { codec => rubydebug }
  elasticsearch {
    host => "localhost"
    protocol => http
  }
}
